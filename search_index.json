[
["index.html", "Targeted Learning with the tlverse Software Ecosystem Workshop, 13 November 2019, Gates Foundation Preface Important links About this workshop Outline About the instructors and authors", " Targeted Learning with the tlverse Software Ecosystem Workshop, 13 November 2019, Gates Foundation Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips updated: November 13, 2019 Preface This is an open source and fully-reproducible electronic vignette for an invited short-course on applying the targeted learning methodology in practice using the tlverse software ecosystem, given at the Gates Foundation on 13 November 2019. The Hitchhiker’s Guide to the tlverse, or a Targeted Learning Practitioner’s Handbook is an in-draft book covering more topics in greater detail and may serve as a useful accompanying resource to these workshop materials. Important links Software installation Please install the relevant software before the workshop. installation script Code R script files for each section of the workshop are available via the GitHub repository for the short course. https://github.com/tlverse/gates2019-workshop/tree/master/handbook/R About this workshop This half-day workshop will provide an introduction to the field of targeted learning and the corresponding tlverse software ecosystem. We will provide a gentle introduction to targeted minimum loss estimators of causal effects. These multiply robust, efficient plug-in estimators use state-of-the-art, ensemble machine learning tools to flexibly adjust for confounding while yielding valid statistical inference. We will discuss the utility of this robust estimation strategy in comparison to conventional techniques, which often rely on restrictive statistical models and may therefore lead to severely biased inference. In addition to discussion, this workshop will incorporate hands-on, guided R programming tutorials using the tlverse, to allow participants the opportunity to familiarize themselves with methodology and tools that will translate to real-world statistical analyses. It is highly recommended for participants to have an understanding of basic statistical concepts such as confounding, probability distributions, confidence intervals, hypothesis tests, and regression. Advanced knowledge of mathematical statistics may be useful but is not necessary. Familiarity with the R programming language will be essential. Outline Topics covered in this workshop will include Introduction to the tlverse software ecosystem Overview of the WASH Benefits data Ensemble machine learning with the sl3 R package Targeted learning for the average treatment effect with the tmle3 R package About the instructors and authors Mark van der Laan Mark van der Laan, Ph.D., is Professor of Biostatistics and Statistics at UC Berkeley. His research interests include statistical methods in computational biology, survival analysis, censored data, adaptive designs, targeted maximum likelihood estimation, causal inference, data-adaptive loss-based learning, and multiple testing. His research group developed loss-based super learning in semiparametric models, based on cross-validation, as a generic optimal tool for the estimation of infinite-dimensional parameters, such as nonparametric density estimation and prediction with both censored and uncensored data. Building on this work, his research group developed targeted maximum likelihood estimation for a target parameter of the data-generating distribution in arbitrary semiparametric and nonparametric models, as a generic optimal methodology for statistical and causal inference. Most recently, Mark’s group has focused in part on the development of a centralized, principled set of software tools for targeted learning, the tlverse. For more information, see https://vanderlaan-lab.org. Jeremy Coyle Jeremy Coyle, Ph.D., is a consulting data scientist and statistical programmer, currently leading the software development effort that has produced the tlverse ecosystem of R packages and related software tools. Jeremy earned his Ph.D. in Biostatistics from UC Berkeley in 2016, primarily under the supervision of Alan Hubbard. Alan Hubbard Alan Hubbard, Ph.D., is Professor of Biostatistics, former head of the Division of Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley’s SuperFund research program. His current research interests include causal inference, variable importance analysis, statistical machine learning, estimation of and inference for data-adaptive statistical target parameters, and targeted minimum loss-based estimation. Research in his group is generally motivated by applications to problems in computational biology, epidemiology, and precision medicine. Nima Hejazi Nima is a Ph.D. candidate in biostatistics with a designated emphasis in computational and genomic biology, working with Mark van der Laan and Alan Hubbard. Nima is affiliated with UC Berkeley’s Center for Computational Biology and is a former NIH Biomedical Big Data fellow. He earned is Master’s in Biostatistics (2017) and a Bachelor’s with a triple major in Molecular and Cell Biology (Neurobiology), Psychology, and Public Health (2015) at UC Berkeley. Nima’s interests span nonparametric estimation, high-dimensional inference, targeted learning, statistical computing, survival analysis, and computational biology, with an emphasis on the development of robust and efficient statistical methodologies that draw on the intersection of causal inference and statistical machine learning. For more information, see https://nimahejazi.org. Ivana Malenica Ivana is a Ph.D. student in biostatistics advised by Mark van der Laan. Ivana is currently a fellow at the Berkeley Institute for Data Science, after serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow. She earned her Master’s in Biostatistics and Bachelor’s in Mathematics, and spent some time at the Translational Genomics Research Institute. Very broadly, her research interests span non/semi-parametric theory, probability theory, machine learning, causal inference and high-dimensional statistics. Most of her current work involves complex dependent settings (dependence through time and network) and adaptive sequential designs. Rachael Phillips Rachael is a Ph.D. student in biostatistics, advised by Alan Hubbard and Mark van der Laan. She has an M.A. in Biostatistics, B.S. in Biology with a Chemistry minor and a B.A. in Mathematics with a Spanish minor. Motivated by issues arising in health care, Rachael leverages strategies rooted in causal inference and nonparametric estimation to build clinician-tailored, machine-driven solutions. Her accompanying statistical interests include high-dimensional statistics and experimental design. She is also passionate about free, online-mediated education. "],
["tlverse.html", "Chapter 1 Welcome to the tlverse 1.1 Learning Objectives 1.2 What is the tlverse? 1.3 tlverse components 1.4 Installation", " Chapter 1 Welcome to the tlverse Jeremy Coyle 1.1 Learning Objectives Understand the tlverse ecosystem conceptually Identify the core components of the tlverse Install tlverse R packages Understand the Targeted Learning roadmap Learn about the WASH Benefits example data 1.2 What is the tlverse? The tlverse is a new framework for doing Targeted Learning in R, inspired by the tidyverse ecosystem of R packages. By analogy to the tidyverse: The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. So, the tlverse is an opinionated collection of R packages for Targeted Learning sharing an underlying philosophy, grammar, and set of data structures 1.3 tlverse components These are the main packages that represent the core of the tlverse: sl3: Modern Super Learning with Pipelines What? A modern object-oriented re-implementation of the Super Learner algorithm, employing recently developed paradigms for R programming. Why? A design that leverages modern tools for fast computation, is forward-looking, and can form one of the cornerstones of the tlverse. tmle3: An Engine for Targeted Learning What? A generalized framework that simplifies Targeted Learning by identifying and implementing a series of common statistical estimation procedures. Why? A common interface and engine that accommodates current algorithmic approaches to Targeted Learning and is still flexible enough to remain the engine even as new techniques are developed. In addition to the engines that drive development in the tlverse, there are some supporting packages – in particular, we have two… origami: A Generalized Framework for Cross-Validation What? A generalized framework for flexible cross-validation Why? Cross-validation is a key part of ensuring error estimates are honest and preventing overfitting. It is an essential part of the both the Super Learner algorithm and Targeted Learning. delayed: Parallelization Framework for Dependent Tasks What? A framework for delayed computations (futures) based on task dependencies. Why? Efficient allocation of compute resources is essential when deploying large-scale, computationally intensive algorithms. A key principle of the tlverse is extensibility. That is, we want to support new Targeted Learning estimators as they are developed. The model for this is new estimators are implemented in additional packages using the core packages above. There are currently two featured examples of this: tmle3mopttx: Optimal Treatments in tlverse What? Learn an optimal rule and estimate the mean outcome under the rule Why? Optimal Treatment is a powerful tool in precision healthcare and other settings where a one-size-fits-all treatment approach is not appropriate. tmle3shift: Shift Interventions in tlverse What? Shift interventions for continuous treatments Why? Not all treatment variables are discrete. Being able to estimate the effects of continuous treatment represents a powerful extension of the Targeted Learning approach. 1.4 Installation The tlverse ecosystem of packages are currently hosted at https://github.com/tlverse, not yet on CRAN. You can use the devtools package to install them: install.packages(&quot;devtools&quot;) devtools::install_github(&quot;tlverse/tlverse&quot;) The tlverse depends on a large number of other packages that are also hosted on GitHub. Because of this, you may see the following error: Error: HTTP error 403. API rate limit exceeded for 71.204.135.82. (But here&#39;s the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.) Rate limit remaining: 0/60 Rate limit reset at: 2019-03-04 19:39:05 UTC To increase your GitHub API rate limit - Use `usethis::browse_github_pat()` to create a Personal Access Token. - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`. This just means that R tried to install too many packages from GitHub in too short of a window. To fix this, you need to tell R how to use GitHub as your user (you’ll need a GitHub user account). Follow these two steps: Type usethis::browse_github_pat() in your R console, which will direct you to GitHub’s page to create a New Personal Access Token. Create a Personal Access Token simply by clicking “Generate token” at the bottom of the page. Copy your Personal Access Token, a long string of lowercase letters and numbers. Type usethis::edit_r_environ() in your R console, which will open your .Renviron file in the source window of RStudio. In your .Renviron file, type GITHUB_PAT= and then paste your Personal Access Token after the equals symbol with no space. In your .Renviron file, press the enter key to ensure that your .Renviron ends with a newline. Save your .Renviron file. Restart R for changes to take effect. You can restart R via the drop-down menu on the “Session” tab. The “Session” tab is at the top of the RStudio interface. After following these steps, you should be able to successfully install the package which threw the error above. This workshop has other dependencies, which you can install using the following linked script: install.R "],
["the-wash-benefits-example-dataset.html", "Chapter 2 The WASH Benefits Example Dataset", " Chapter 2 The WASH Benefits Example Dataset The data come from a study of the effect of water quality, sanitation, hand washing, and nutritional interventions on child development in rural Bangladesh (WASH Benefits Bangladesh): a cluster-randomised controlled trial (Luby et al. 2018). The study enrolled pregnant women in their first or second trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and Tangail districts of central Bangladesh, with an average of eight women per cluster. Groups of eight geographically adjacent clusters were block-randomised, using a random number generator, into six intervention groups (all of which received weekly visits from a community health promoter for the first 6 months and every 2 weeks for the next 18 months) and a double-sized control group (no intervention or health promoter visit). The six intervention groups were: chlorinated drinking water; improved sanitation; hand-washing with soap; combined water, sanitation, and hand washing; improved nutrition through counseling and provision of lipid-based nutrient supplements; and combined water, sanitation, handwashing, and nutrition. In the workshop, we concentrate on child growth (size for age) as the outcome of interest. For reference, this trial was registered with ClinicalTrials.gov as NCT01590095. library(tidyverse) # read in data dat &lt;- read_csv(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;) dat # A tibble: 4,695 x 28 whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 0 Cont… N05265 9 268 male 30 Prima… 146. Food S… 3 2 -1.16 Cont… N05265 9 286 male 25 Prima… 149. Modera… 2 3 -1.05 Cont… N08002 9 264 male 25 Prima… 152. Food S… 1 4 -1.26 Cont… N08002 9 252 fema… 28 Prima… 140. Food S… 3 5 -0.59 Cont… N06531 9 336 fema… 19 Secon… 151. Food S… 2 6 -0.51 Cont… N06531 9 304 male 20 Secon… 154. Severe… 0 7 -2.46 Cont… N08002 9 336 fema… 19 Prima… 151. Food S… 2 8 -0.6 Cont… N06528 9 312 fema… 25 No ed… 142. Food S… 2 9 -0.23 Cont… N06528 9 322 male 30 Secon… 153. Food S… 1 10 -0.14 Cont… N06453 9 376 male 30 No ed… 156. Modera… 2 # … with 4,685 more rows, and 17 more variables: Ncomp &lt;dbl&gt;, watmin &lt;dbl&gt;, # elec &lt;dbl&gt;, floor &lt;dbl&gt;, walls &lt;dbl&gt;, roof &lt;dbl&gt;, asset_wardrobe &lt;dbl&gt;, # asset_table &lt;dbl&gt;, asset_chair &lt;dbl&gt;, asset_khat &lt;dbl&gt;, asset_chouki &lt;dbl&gt;, # asset_tv &lt;dbl&gt;, asset_refrig &lt;dbl&gt;, asset_bike &lt;dbl&gt;, asset_moto &lt;dbl&gt;, # asset_sewmach &lt;dbl&gt;, asset_mobile &lt;dbl&gt; For the purposes of this workshop, we we start by treating the data as independent and identically distributed (i.i.d.) random draws from a very large target population. We could, with available options, account for the clustering of the data (within sampled geographic units), but, for simplification, we avoid these details in these workshop presentations, although modifications of our methodology for biased samples, repeated measures, etc., are available. We have 28 variables measured, of which 1 variable is set to be the outcome of interest. This outcome, \\(Y\\), is the weight-for-height Z-score (whz in dat); the treatment of interest, \\(A\\), is the randomized treatment group (tr in dat); and the adjustment set, \\(W\\), consists simply of everything else. This results in our observed data structure being \\(n\\) i.i.d. copies of \\(O_i = (W_i, A_i, Y_i)\\), for \\(i = 1, \\ldots, n\\). Using the skimr package, we can quickly summarize the variables measured in the WASH Benefits data set: library(skimr) skim(dat) Skim summary statistics n obs: 4695 n variables: 28 ── Variable type:character ───────────────────────────────────────────────────── variable missing complete n min max empty n_unique fracode 0 4695 4695 2 6 0 20 hfiacat 0 4695 4695 11 24 0 4 momedu 0 4695 4695 12 15 0 3 sex 0 4695 4695 4 6 0 2 tr 0 4695 4695 3 15 0 7 ── Variable type:numeric ─────────────────────────────────────────────────────── variable missing complete n mean sd p0 p25 p50 p75 aged 0 4695 4695 266.32 52.17 42 230 266 303 asset_bike 0 4695 4695 0.32 0.47 0 0 0 1 asset_chair 0 4695 4695 0.73 0.44 0 0 1 1 asset_chouki 0 4695 4695 0.78 0.41 0 1 1 1 asset_khat 0 4695 4695 0.61 0.49 0 0 1 1 asset_mobile 0 4695 4695 0.86 0.35 0 1 1 1 asset_moto 0 4695 4695 0.066 0.25 0 0 0 0 asset_refrig 0 4695 4695 0.079 0.27 0 0 0 0 asset_sewmach 0 4695 4695 0.065 0.25 0 0 0 0 asset_table 0 4695 4695 0.73 0.44 0 0 1 1 asset_tv 0 4695 4695 0.3 0.46 0 0 0 1 asset_wardrobe 0 4695 4695 0.17 0.37 0 0 0 0 elec 0 4695 4695 0.6 0.49 0 0 1 1 floor 0 4695 4695 0.11 0.31 0 0 0 0 momage 18 4677 4695 23.91 5.24 14 20 23 27 momheight 31 4664 4695 150.5 5.23 120.65 147.05 150.6 154.06 month 0 4695 4695 6.45 3.33 1 4 6 9 Ncomp 0 4695 4695 11.04 6.35 2 6 10 14 Nlt18 0 4695 4695 1.6 1.25 0 1 1 2 roof 0 4695 4695 0.99 0.12 0 1 1 1 walls 0 4695 4695 0.72 0.45 0 0 1 1 watmin 0 4695 4695 0.95 9.48 0 0 0 1 whz 0 4695 4695 -0.59 1.03 -4.67 -1.28 -0.6 0.08 p100 hist 460 ▁▁▂▇▇▅▁▁ 1 ▇▁▁▁▁▁▁▃ 1 ▃▁▁▁▁▁▁▇ 1 ▂▁▁▁▁▁▁▇ 1 ▅▁▁▁▁▁▁▇ 1 ▁▁▁▁▁▁▁▇ 1 ▇▁▁▁▁▁▁▁ 1 ▇▁▁▁▁▁▁▁ 1 ▇▁▁▁▁▁▁▁ 1 ▃▁▁▁▁▁▁▇ 1 ▇▁▁▁▁▁▁▃ 1 ▇▁▁▁▁▁▁▂ 1 ▆▁▁▁▁▁▁▇ 1 ▇▁▁▁▁▁▁▁ 60 ▅▇▅▂▁▁▁▁ 168 ▁▁▁▂▇▇▂▁ 12 ▅▃▇▃▂▇▃▅ 52 ▇▇▃▁▁▁▁▁ 10 ▇▃▂▁▁▁▁▁ 1 ▁▁▁▁▁▁▁▇ 1 ▃▁▁▁▁▁▁▇ 600 ▇▁▁▁▁▁▁▁ 4.97 ▁▁▅▇▃▁▁▁ A convenient summary of the relevant variables is given just above, complete with a small visualization describing the marginal characteristics of each covariate. Note that the asset variables reflect socio-economic status of the study participants. Notice also the uniform distribution of the treatment groups (with twice as many controls); this is, of course, by design. References "],
["super-ensemble-machine-learning.html", "Chapter 3 Super (Ensemble Machine) Learning 3.1 Introduction 3.2 Learning Objectives 3.3 Streamlined sl3 Implementation 3.4 Extensions 3.5 Exercise 3.6 Summary", " Chapter 3 Super (Ensemble Machine) Learning Ivana Malenica and Rachael Phillips Based on the sl3 R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica, and Oleg Sofrygin. Updated: 2019-11-13 3.1 Introduction Once the statistical estimation problem is defined, as described in the The Targeted Learning Roadmap, we are ready to construct the TMLE: an asymptotically efficient substitution estimator of this target quantity. The first step in the estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the super learner (van der Laan, Polley, and Hubbard 2007), an important step for creating a robust estimator. 3.1.1 Super Learning A common task in statistical data analysis is estimator selection (e.g., for prediction). There is no universally optimal machine learning algorithm for density estimation or prediction. For some data, one needs learners that can model a complex function. For others, possibly as a result of noise or insufficient sample size, a simple, parametric model might fit best. Super Learner, an ensemble learner, solves this issue, by allowing a combination of learners from the simplest (intercept-only) to most complex (neural nets, random forests, SVM, etc). It works by using cross-validation in a manner which guarantees that the resulting fit will be as good as possible, given the learners provided. Note: even a combination of poor learners can sometimes result in good fit. It is very important to have good candidates in our library, possibly incorporating known knowledge about the system in question. 3.1.1.1 General Overview of the Algorithm What is cross-validation and how does it work? There are many different cross-validation schemes, designed to accommodate different study designs and data structures. The figure below shows an example of 10-fold cross-validation. knitr::include_graphics(&quot;img/misc/vs.pdf&quot;) General step-by-step overview of the Super Learner algorithm: Break up the sample evenly into V-folds (say V=10). For each of these 10 folds, remove that portion of the sample (kept out as validation sample) and the remaining will be used to fit learners (training sample). Fit each learner on the training sample (note, some learners will have their own internal cross-validation procedure or other methods to select tuning parameters). For each observation in the corresponding validation sample, predict the outcome using each of the learners, so if there are \\(p\\) learners, then there would be \\(p\\) predictions. Take out another validation sample and repeat until each of the V-sets of data are removed. Compare the cross-validated fit of the learners across all observations based on specified loss function (e.g., squared error, negative log-likelihood, …) by calculating the corresponding average loss (risk). Either: choose the learner with smallest risk and apply that learner to entire data set (resulting SL fit), do a weighted average of the learners to minimize the cross-validated risk (construct an ensemble of learners), by re-fitting the learners on the original data set, and use the weights above to get the SL fit. Note, this entire procedure can be itself cross-validated to get a consistent estimate of the future performance of the SL fit. How to pick a Super Learner library? A library is simply a collection of algorithms. The algorithms in the library should come from contextual knowledge and a large set of “default” algorithms. The algorithms may range from a simple linear regression model to multi-step algorithms involving screening covariates, penalizations, optimizing tuning parameters, etc. 3.1.1.2 Example: Super Learner In Prediction We observe a learning data set \\(X_i=(Y_i,W_i)\\), for \\(i=1, ..., n\\). Here, \\(Y_i\\) is the outcome of interest, and \\(W_i\\) is a p-dimensional set of covariates. Our objective is to estimate the function \\(\\psi_0(W) = E(Y|W)\\). This function can be expressed as the minimizer of the expected loss: \\(\\psi_0(W) = \\text{argmin}_{\\psi} E[L(X,\\psi(W))]\\). Here, the loss function is represented as \\(L\\) (e.g., squared error loss, \\(L: (Y-\\psi(W)))\\)). 3.1.1.3 Why use the Super Learner? For prediction, one can use the cross-validated risk to empirically determine the relative performance of SL and competing methods. When we have tested different algorithms on actual data and looked at the performance (e.g., MSE of prediction), never does one algorithm always win (see below). Below shows the results of such a study, comparing the fits of several different learners, including the SL algorithms. Super Learner performs asymptotically as well as best possible weighted combination. By including all competitors in the library of candidate estimators (glm, neural nets, SVMs, random forest, etc.), the Super Learner will asymptotically outperform any of its competitors- even if the set of competitors is allowed to grow polynomial in sample size. Motivates the name “Super Learner”: it provides a system of combining many estimators into an improved estimator. Review of the Super Learner Loss-function-based tool that uses V-fold cross-validation to obtain the best prediction of the relevant part of the likelihood that’s needed to evaluate target parameter. Requires expressing the estimand as the minimizer of an expected loss, and proposing a library of algorithms (“learners” in sl3 nomenclature) that we think might be consistent with the true data-generating distribution. The discrete super learner, or cross-validated selector, is the algorithm in the library that minimizes the V-fold cross-validated empirical risk. The super learner is a weighted average of the library of algorithms, where the weights are chosen to minimize the V-fold cross-validated empirical risk of the library. Restricting the weights (“metalearner” in sl3 nomenclature) to be positive and sum to one (convex combination) has been shown to improve upon the discrete super learner (Polley and van der Laan 2010; van der Laan, Polley, and Hubbard 2007). Proven to be asymptotically as accurate as the best possible prediction algorithm that is tested (van der Laan and Dudoit 2003; van der Vaart, Dudoit, and van der Laan 2006). This background material is described in greater detail in the accompanying tlverse handbook sl3 chapter. 3.2 Learning Objectives By the end of this lesson you will be able to: Assemble an ensemble of learners based on the properties that identify what features they support. Customize learner hyperparameters to incorporate a diversity of different settings. Select a subset of available covariates and pass only those variables to the modeling algorithm. Fit an ensemble with nested cross-validation to obtain an estimate of the performance of the ensemble itself. Calculate sl3 variable importance metrics. Interpret the discrete and continuous super learner fits. Rationalize the need to remove bias from the super learner to make an optimal bias-variance tradeoff for the parameter of interest. 3.3 Streamlined sl3 Implementation We begin by illustrating the core functionality of the super learner algorithm as implemented in sl3. The sl3 implementation consists of the following steps: Load the necessary libraries and data Define the machine learning task Make a super learner by creating library of base learners and a metalearner Train the super learner on the machine learning task Obtain predicted values WASH Benefits Study Example Using the WASH data, we are interested in predicting weight-for-height z-score whz using the available covariate data. 0. Load the necessary libraries and data library(kableExtra) library(knitr) library(skimr) library(tidyverse) library(data.table) library(sl3) library(SuperLearner) library(origami) set.seed(7194) # load data set and take a peek washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE ) head(washb_data) %&gt;% kable(digits = 4) %&gt;% kable_styling(fixed_thead = T, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;250px&quot;) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp watmin elec floor walls roof asset_wardrobe asset_table asset_chair asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto asset_sewmach asset_mobile 0.00 Control N05265 9 268 male 30 Primary (1-5y) 146.40 Food Secure 3 11 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 -1.16 Control N05265 9 286 male 25 Primary (1-5y) 148.75 Moderately Food Insecure 2 4 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 -1.05 Control N08002 9 264 male 25 Primary (1-5y) 152.15 Food Secure 1 10 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 -1.26 Control N08002 9 252 female 28 Primary (1-5y) 140.25 Food Secure 3 5 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 -0.59 Control N06531 9 336 female 19 Secondary (&gt;5y) 150.95 Food Secure 2 7 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 -0.51 Control N06531 9 304 male 20 Secondary (&gt;5y) 154.20 Severely Food Insecure 0 3 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1. Define the machine learning task To define the machine learning “task” (predict weight-for-height z-score whz using the available covariate data), we need to create an sl3_Task object. The sl3_Task keeps track of the roles the variables play in the machine learning problem, the data, and any metadata (e.g., observational-level weights, id, offset). # specify the outcome and covariates outcome &lt;- &quot;whz&quot; covars &lt;- colnames(washb_data)[-which(names(washb_data) == outcome)] # create the sl3 task washb_task &lt;- make_sl3_Task( data = washb_data, covariates = covars, outcome = outcome ) Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data Found. Imputing covariates using sl3_process_missing. # examine the task washb_task A sl3 Task with 4695 obs and these nodes: $covariates [1] &quot;tr&quot; &quot;fracode&quot; &quot;month&quot; &quot;aged&quot; [5] &quot;sex&quot; &quot;momage&quot; &quot;momedu&quot; &quot;momheight&quot; [9] &quot;hfiacat&quot; &quot;Nlt18&quot; &quot;Ncomp&quot; &quot;watmin&quot; [13] &quot;elec&quot; &quot;floor&quot; &quot;walls&quot; &quot;roof&quot; [17] &quot;asset_wardrobe&quot; &quot;asset_table&quot; &quot;asset_chair&quot; &quot;asset_khat&quot; [21] &quot;asset_chouki&quot; &quot;asset_tv&quot; &quot;asset_refrig&quot; &quot;asset_bike&quot; [25] &quot;asset_moto&quot; &quot;asset_sewmach&quot; &quot;asset_mobile&quot; &quot;delta_momage&quot; [29] &quot;delta_momheight&quot; $outcome [1] &quot;whz&quot; $id NULL $weights NULL $offset NULL 2. Make a super learner Now that we have defined our machine learning problem with the task, we are ready to “make” the super learner. This requires specification of Base learning algorithms, to establish a library of learners that we think might be consistent with the true data-generating distribution. Metalearner, to ensemble the base learners. We might also incorporate Feature selection, to pass only a subset of the predictors to the algorithm. Hyperparameter specification, to tune base learners. Learners have properties that indicate what features they support. We may use sl3_list_properties() to get a list of all properties supported by at least one learner. sl3_list_properties() [1] &quot;binomial&quot; &quot;categorical&quot; &quot;continuous&quot; [4] &quot;cv&quot; &quot;density&quot; &quot;ids&quot; [7] &quot;multivariate_outcome&quot; &quot;offset&quot; &quot;preprocessing&quot; [10] &quot;timeseries&quot; &quot;weights&quot; &quot;wrapper&quot; Since we have a continuous outcome, we may identify the learners that support this outcome type with sl3_list_learners(). sl3_list_learners(c(&quot;continuous&quot;)) [1] &quot;Lrnr_arima&quot; &quot;Lrnr_bartMachine&quot; [3] &quot;Lrnr_bilstm&quot; &quot;Lrnr_caret&quot; [5] &quot;Lrnr_condensier&quot; &quot;Lrnr_dbarts&quot; [7] &quot;Lrnr_earth&quot; &quot;Lrnr_expSmooth&quot; [9] &quot;Lrnr_gam&quot; &quot;Lrnr_gbm&quot; [11] &quot;Lrnr_glm&quot; &quot;Lrnr_glm_fast&quot; [13] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [15] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [17] &quot;Lrnr_hal9001&quot; &quot;Lrnr_HarmonicReg&quot; [19] &quot;Lrnr_lstm&quot; &quot;Lrnr_mean&quot; [21] &quot;Lrnr_nnls&quot; &quot;Lrnr_optim&quot; [23] &quot;Lrnr_pkg_SuperLearner&quot; &quot;Lrnr_pkg_SuperLearner_method&quot; [25] &quot;Lrnr_pkg_SuperLearner_screener&quot; &quot;Lrnr_polspline&quot; [27] &quot;Lrnr_randomForest&quot; &quot;Lrnr_ranger&quot; [29] &quot;Lrnr_rpart&quot; &quot;Lrnr_rugarch&quot; [31] &quot;Lrnr_solnp&quot; &quot;Lrnr_stratified&quot; [33] &quot;Lrnr_svm&quot; &quot;Lrnr_tsDyn&quot; [35] &quot;Lrnr_xgboost&quot; Now that we have an idea of some learners, we can construct them using the make_learner function. # choose base learners lrnr_glm &lt;- make_learner(Lrnr_glm) lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_glmnet &lt;- make_learner(Lrnr_glmnet) We can customize learner hyperparameters to incorporate a diversity of different settings. Documentation for the learners and their hyperparameters can be found in the sl3 Learners Reference. We can also include learners from the SuperLearner R package. lrnr_ranger100 &lt;- make_learner(Lrnr_ranger, num.trees = 100) lrnr_hal_simple &lt;- make_learner(Lrnr_hal9001, degrees = 1, n_folds = 2) lrnr_gam &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.gam&quot;) lrnr_bayesglm &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.bayesglm&quot;) In order to assemble the library of learners, we need to “stack” them together. A Stack is a special learner and it has the same interface as all other learners. What makes a stack special is that it combines multiple learners by training them simultaneously, so that their predictions can be either combined or compared. stack &lt;- make_learner( Stack, lrnr_glm, lrnr_mean, lrnr_ranger100, lrnr_glmnet, lrnr_gam, lrnr_bayesglm ) We will fit a non-negative least squares metalearner using Lrnr_nnls. Note that any learner can be used as a metalearner. metalearner &lt;- make_learner(Lrnr_nnls) We can optionally select a subset of available covariates and pass only those variables to the modeling algorithm. Let’s consider screening covariates based on their correlation with our outcome of interest (cor.test p-value \\(\\leq 0.1\\)). screen_cor &lt;- Lrnr_pkg_SuperLearner_screener$new(&quot;screen.corP&quot;) # which covariates are selected on the full data? screen_cor$train(washb_task) Warning: `lang_tail()` is deprecated as of rlang 0.2.0. This warning is displayed once per session. Warning: `mut_node_cdr()` is deprecated as of rlang 0.2.0. This warning is displayed once per session. [1] &quot;Lrnr_pkg_SuperLearner_screener_screen.corP&quot; $selected [1] &quot;tr&quot; &quot;fracode&quot; &quot;aged&quot; &quot;momage&quot; [5] &quot;momedu&quot; &quot;momheight&quot; &quot;hfiacat&quot; &quot;Nlt18&quot; [9] &quot;elec&quot; &quot;floor&quot; &quot;walls&quot; &quot;asset_wardrobe&quot; [13] &quot;asset_table&quot; &quot;asset_chair&quot; &quot;asset_khat&quot; &quot;asset_chouki&quot; [17] &quot;asset_tv&quot; &quot;asset_refrig&quot; &quot;asset_moto&quot; &quot;asset_sewmach&quot; [21] &quot;asset_mobile&quot; To “pipe” only the selected covariates to the modeling algorithm, we need to make a Pipeline, which is a just set of learners to be fit sequentially, where the fit from one learner is used to define the task for the next learner. cor_pipeline &lt;- make_learner(Pipeline, screen_cor, stack) Now our learners will be preceded by a screening step. We also consider the original stack, just to compare how the feature selection methods perform in comparison to the methods without feature selection. Analogous to what we have seen before, we have to stack the pipeline and original stack together, so we may use them as base learners in our super learner. fancy_stack &lt;- make_learner(Stack, cor_pipeline, stack) # we can visualize the stack dt_stack &lt;- delayed_learner_train(fancy_stack, washb_task) plot(dt_stack, color = FALSE, height = &quot;400px&quot;, width = &quot;100%&quot;) We have made a library/stack of base learners and a metalearner, so we are ready to make the super learner. The super learner algorithm fits a metalearner on the validation-set predictions. sl &lt;- make_learner(Lrnr_sl, learners = fancy_stack, metalearner = metalearner ) # we can visualize the super learner dt_sl &lt;- delayed_learner_train(sl, washb_task) plot(dt_sl, color = FALSE, height = &quot;400px&quot;, width = &quot;100%&quot;) ### 3. Train the super learner on the machine learning task {-} Now we are ready to “train” our super learner on our sl3_task object, washb_task. sl_fit &lt;- sl$train(washb_task) 4. Obtain predicted values Now that we have fit the super learner, we are ready to obtain our predicted values, and we can also obtain a summary of the results. sl_preds &lt;- sl_fit$predict() head(sl_preds) [1] -0.5593961 -0.8902979 -0.7620500 -0.7520223 -0.6772905 -0.7270881 sl_fit$print() [1] &quot;SuperLearner:&quot; List of 2 $ : chr &quot;Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)&quot; $ : chr &quot;Stack&quot; [1] &quot;Lrnr_nnls&quot; lrnrs 1: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE 2: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean 3: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE_1 4: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 5: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam 6: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm 7: Stack_Lrnr_glm_TRUE 8: Stack_Lrnr_mean 9: Stack_Lrnr_ranger_100_TRUE_1 10: Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 11: Stack_Lrnr_pkg_SuperLearner_SL.gam 12: Stack_Lrnr_pkg_SuperLearner_SL.bayesglm weights 1: 0.00000000 2: 0.00000000 3: 0.24227474 4: 0.00000000 5: 0.17317121 6: 0.00000000 7: 0.03004505 8: 0.00000000 9: 0.23168399 10: 0.32880148 11: 0.00000000 12: 0.00000000 [1] &quot;Cross-validated risk (MSE, squared error loss):&quot; learner 1: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE 2: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean 3: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE_1 4: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 5: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam 6: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm 7: Stack_Lrnr_glm_TRUE 8: Stack_Lrnr_mean 9: Stack_Lrnr_ranger_100_TRUE_1 10: Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 11: Stack_Lrnr_pkg_SuperLearner_SL.gam 12: Stack_Lrnr_pkg_SuperLearner_SL.bayesglm 13: SuperLearner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk 1: NA 1.015128 0.02363317 0.07629401 0.8927540 1.131594 2: NA 1.065282 0.02502664 0.09191791 0.9264292 1.196647 3: NA 1.019206 0.02362484 0.08100156 0.8753326 1.150568 4: NA 1.012689 0.02359874 0.07894330 0.8821712 1.130862 5: NA 1.015128 0.02363317 0.07629401 0.8927540 1.131594 6: NA 1.015119 0.02363328 0.07631510 0.8926608 1.131570 7: NA 1.018612 0.02380402 0.07799191 0.8956048 1.134940 8: NA 1.065282 0.02502664 0.09191791 0.9264292 1.196647 9: NA 1.017700 0.02343712 0.07829554 0.8826330 1.136717 10: NA 1.012201 0.02358054 0.07946680 0.8826979 1.130414 11: NA 1.018612 0.02380402 0.07799191 0.8956048 1.134940 12: NA 1.018596 0.02380414 0.07801948 0.8954820 1.134909 13: NA 1.006207 0.02339759 0.07868666 0.8729051 1.127880 3.4 Extensions 3.4.1 Cross-validated Super Learner We can cross-validate the super learner to see how well the super learner performs on unseen data, and obtain an estimate of the cross-validated risk of the super learner. This estimation procedure requires an “external” layer of cross-validation, also called nested cross-validation, which involves setting aside a separate holdout sample that we don’t use to fit the super learner. This external cross-validation procedure may also incorporate 10 folds, which is the default in sl3. However, we will incorporate 2 outer/external folds of cross-validation for computational efficiency. We also need to specify a loss function to evaluate super learner. Documentation for the available loss functions can be found in the sl3 Loss Function Reference. washb_task_new &lt;- make_sl3_Task( data = washb_data, covariates = covars, outcome = outcome, folds = make_folds(washb_data, fold_fun = folds_vfold, V = 2) ) Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data Found. Imputing covariates using sl3_process_missing. CVsl &lt;- CV_lrnr_sl(sl_fit, washb_task_new, loss_squared_error) CVsl %&gt;% kable(digits = 4) %&gt;% kable_styling(fixed_thead = T, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;250px&quot;) learner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE NA 1.0317 0.0240 0.0086 1.0256 1.0378 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean NA 1.0653 0.0250 0.0179 1.0526 1.0779 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE_1 NA 1.0354 0.0240 0.0067 1.0306 1.0401 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE NA 1.0170 0.0237 0.0176 1.0046 1.0294 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam NA 1.0317 0.0240 0.0086 1.0256 1.0378 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm NA 1.0317 0.0240 0.0086 1.0255 1.0378 Stack_Lrnr_glm_TRUE NA 1.0502 0.0284 0.0157 1.0392 1.0613 Stack_Lrnr_mean NA 1.0653 0.0250 0.0179 1.0526 1.0779 Stack_Lrnr_ranger_100_TRUE_1 NA 1.0218 0.0235 0.0101 1.0146 1.0289 Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE NA 1.0191 0.0238 0.0119 1.0107 1.0275 Stack_Lrnr_pkg_SuperLearner_SL.gam NA 1.0502 0.0284 0.0157 1.0392 1.0613 Stack_Lrnr_pkg_SuperLearner_SL.bayesglm NA 1.0502 0.0285 0.0157 1.0391 1.0613 SuperLearner NA 1.0162 0.0236 0.0135 1.0067 1.0257 3.4.2 Variable Importance Measures with sl3 The sl3 varimp function returns a table with variables listed in decreasing order of importance, in which the measure of importance is based on a risk difference between the learner fit with a permuted covariate and the learner fit with the true covariate, across all covariates. In this manner, the larger the risk difference, the more important the variable is in the prediction. washb_varimp &lt;- varimp(sl_fit, loss_squared_error) washb_varimp %&gt;% kable(digits = 4) %&gt;% kable_styling(fixed_thead = T, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;250px&quot;) X risk_diff aged 0.0379 momedu 0.0087 tr 0.0051 momheight 0.0049 month 0.0047 asset_refrig 0.0035 floor 0.0035 asset_chair 0.0031 Nlt18 0.0029 elec 0.0022 asset_chouki 0.0022 asset_moto 0.0009 asset_khat 0.0008 walls 0.0007 fracode 0.0007 momage 0.0006 sex 0.0004 hfiacat 0.0004 asset_wardrobe 0.0003 asset_table 0.0000 delta_momage 0.0000 asset_tv -0.0001 roof -0.0001 delta_momheight -0.0002 asset_bike -0.0003 watmin -0.0003 asset_mobile -0.0005 asset_sewmach -0.0010 Ncomp -0.0014 3.5 Exercise 3.5.1 Predicting Myocardial Infarction with sl3 Follow the steps below to predict myocardial infarction (mi) using the available covariate data. We thank Prof. David Benkeser at Emory University for making the this Cardiovascular Health Study (CHS) data accessible. Work with a buddy/team. You have 20 minutes. In the etherpad, submit your group’s answers to the following questions. Which learner was the discrete super learner? What was the cross validated mean risk of the discrete super learner? What was the cross-validated risk of the continuous super learner? Did your group face any challenges? Any additional comments/questions about this sl3 section of the workshop? # load the data set db_data &lt;- url(&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;) chspred &lt;- read_csv(file = db_data, col_names = TRUE) # take a quick peek head(chspred) %&gt;% kable(digits = 4) %&gt;% kable_styling(fixed_thead = T, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;200px&quot;) waist alcoh hdl beta smoke ace ldl bmi aspirin gend age estrgn glu ins cysgfr dm fetuina whr hsed race logcystat logtrig logcrp logcre health logkcal sysbp mi 110.1642 0.0000 66.4974 0 0 1 114.2162 27.9975 0 0 73.5179 0 159.9314 70.3343 75.0078 1 0.1752 1.1690 1 1 -0.3420 5.4063 2.0126 -0.6739 0 4.3926 177.1345 0 89.9763 0.0000 50.0652 0 0 0 103.7766 20.8931 0 0 61.7723 0 153.3888 33.9695 82.7433 1 0.5717 0.9011 0 0 -0.0847 4.8592 3.2933 -0.5551 1 6.2071 136.3742 0 106.1941 8.4174 40.5059 0 0 0 165.7158 28.4554 1 1 72.9312 0 121.7145 -17.3017 74.6989 0 0.3517 1.1797 0 1 -0.4451 4.5088 0.3013 -0.0115 0 6.7320 135.1993 0 90.0566 0.0000 36.1750 0 0 0 45.2035 23.9608 0 0 79.1191 0 53.9691 11.7315 95.7823 0 0.5439 1.1360 0 0 -0.4807 5.1832 3.0243 -0.5751 1 7.3972 139.0182 0 78.6143 2.9790 71.0642 0 1 0 131.3121 10.9656 0 1 69.0179 0 94.3153 9.7112 72.7109 0 0.4916 1.1028 1 0 0.3121 4.2190 -0.7057 0.0053 1 8.2779 88.0470 0 91.6593 0.0000 59.4963 0 0 0 171.1872 29.1317 0 1 81.8346 0 212.9066 -28.2269 69.2184 1 0.4621 0.9529 1 0 -0.2872 5.1773 0.9705 0.2127 1 5.9942 69.5943 0 Create an sl3 task, setting myocardial infarction mi as the outcome and using all available covariate data. Make a library of seven relatively fast base learning algorithms (i.e., do not consider BART or HAL). Customize hyperparameters for one of your learners. Feel free to use learners from sl3 or SuperLearner. You may use the same base learning library that is presented above. Incorporate feature selection with the SuperLearner screener screen.corP. Fit the metalearning step with non-negative least squares, Lrnr_nnls. With the metalearner and base learners, make the super learner and train it on the task. Print your super learner fit by calling print() with $. Cross-validate your super learner fit to see how well it performs on unseen data. Specify loss_squared_error as the loss function to evaluate the super learner. Like above, create a new task with 2 folds of external cross-validation for computational efficiency. 3.6 Summary The general ensemble learning approach of super learner can be applied to a diversity of estimation and prediction problems that can be defined by a loss function. Plug-in estimators of the estimand are desirable because a plug-in estimator respects both the local and global constraints of the statistical model. Asymptotically linear estimators are also advantageous, since they converge to the estimand at \\(\\frac{1}{\\sqrt{n}}\\) rate, and thereby permit formal statistical inference. If we plug in the estimator returned by super learner into the target parameter mapping, then we would end up with an estimator that has the same bias as what we plugged in. This estimator would not be asymptotically linear. Targeted maximum likelihood estimation (TMLE) is a general strategy that succeeds in constructing asymptotically linear plug-in estimators. In the chapters that follow, we focus on the targeted maximum likelihood estimator and the targeted minimum loss-based estimator, both referred to as TMLE. References "],
["the-tmle-framework.html", "Chapter 4 The TMLE Framework 4.1 Introduction 4.2 Learning Objectives 4.3 Easy-Bake Example: tmle3 for ATE 4.4 tmle3 Components 4.5 Fitting tmle3 with multiple parameters 4.6 Stratified Effect Estimates 4.7 Exercise 4.8 Summary", " Chapter 4 The TMLE Framework Mark van der Laan and Nima Hejazi Based on the tmle3 R package. Updated: 2019-11-13 4.1 Introduction The first step in the estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the super learner (van der Laan, Polley, and Hubbard 2007), as described in the previous section. With the initial estimate of relevent parts of the data-generating distribution necessary to evaluate the target parameter, we are ready to construct the TMLE! 4.1.1 Substitution Estimators Beyond a fit of the prediction function, one might also want to estimate more targeted parameters specific to certain scientific questions. The approach is to plug into the estimand of interest estimates of the relevant distributions. Sometimes, we can use simple empirical distributions, but averaging some function over the observations (e.g., giving weight \\(1/n\\) for all observations). Other parts of the distribution, like conditional means or probabilities, the estimate will require some sort of smoothing due to the curse of dimensionality. We give one example using an example of the average treatment effect (see above): \\(\\Psi(P_0) = \\Psi(Q_0) = \\mathbb{E}_0 \\big[\\mathbb{E}_0[Y \\mid A = 1, W] - \\mathbb{E}_0[Y \\mid A = 0, W]\\big]\\), where \\(Q_0\\) represents both the distribution of \\(Y \\mid A,W\\) and distribution of \\(W\\). Let \\(\\bar{Q}_0(A,W) \\equiv E_0(Y \\mid A,W)\\) and \\(Q_{0,W}(w) = P_0 (W=w)\\), then \\[ \\Psi(Q_0) = \\sum_w \\{ \\bar{Q}_0(1,w)-\\bar{Q}_0(0,w)\\} Q_{0,W}(w) \\] The Substitution Estimator plugs in the empirical distribution (weight \\(1/n\\) for each observation) for \\(Q_{0,W}(W_i)\\), and some estimate of the regression of \\(Y\\) on \\((A,W)\\) (say SL fit): \\[ \\Psi(Q_n) = \\frac{1}{n} \\sum_{i=1}^n \\{ \\bar{Q}_n(1,W_i)-\\bar{Q}_n(0,W_i)\\} \\] Thus, it becomes the average of the differences in predictions from the fit keeping the observed \\(W\\), but first replacing \\(A=1\\) and then the same but all \\(A=0\\). 4.1.2 TMLE Though using SL over an arbitrary parametric regression is an improvement, it’s not sufficient to have the properties of an estimator one needs for rigorous inference. Because the variance-bias trade-off in the SL is focused on the prediction model, it can, for instance, under-fit portions of the distributions that are critical for estimating the parameter of interest, \\(\\Psi(P_0)\\). TMLE keeps the benefits of substitution estimators (it is one), but augments the original estimates to correct for this issue and also results in an asymptotically linear (and thus normally-distributed) estimator with consistent Wald-style confidence intervals. Produces a well-defined, unbiased, efficient substitution estimator of target parameters of a data-generating distribution. Updates an initial (super learner) estimate of the relevant part of the data-generating distribution possibly using an estimate of a nuisance parameter (like the model of intervention given covariates). Removes asymptotic residual bias of initial estimator for the target parameter, if it uses a consistent estimator of \\(g_0\\). If initial estimator was consistent for the target parameter, the additional fitting of the data in the targeting step may remove finite sample bias, and preserves consistency property of the initial estimator. If the initial estimator and the estimator of \\(g_0\\) are both consistent, then it is also asymptotically efficient according to semi-parametric statistical model efficiency theory. Thus, every effort is made to achieve minimal bias and the asymptotic semi-parametric efficiency bound for the variance. There are different types of TMLE, sometimes for the same set of parameters, but below is an example of the algorithm for estimating the ATE. In this case, one can present the estimator as: \\[ \\Psi(Q^{\\star}_n) = \\frac{1}{n} \\sum_{i=1}^n \\{ \\bar{Q}^{\\star}_n(1,W_i) - \\bar{Q}^{\\star}_n(0,W_i)\\} \\] where \\(\\bar{Q}^{\\star}_n(A,W)\\) is the TMLE augmented estimate. \\(f(\\bar{Q}^{\\star}_n(A,W)) = f(\\bar{Q}_n(A,W)) + \\epsilon_n \\cdot h_n(A,W)\\), where \\(f(\\cdot)\\) is the appropriate link function (e.g., logit), \\(\\epsilon_n\\) is an estimated coefficient and \\(h_n(A,W)\\) is a “clever covariate”. In this case, \\(h_n(A,W) = \\frac{A}{g_n(W)}-\\frac{1-A}{1-g_n(W)}\\), with \\(g_n(W) = P_n(A=1 \\mid W)\\) being the estimated (also by SL) propensity score, so the estimator depends both on initial SL fit of the outcome regression (\\(\\bar{Q}_0\\)) and an SL fit of the propensity score (\\(g_n\\)). There are further robust augmentations that are used in tlverse, such as an added layer of cross-validation to avoid over-fitting bias (CV-TMLE), and so called methods that can more robustly estimated several parameters simultaneously (e.g., the points on a survival curve). 4.1.3 Inference The estimators we discuss are asymptotically linear, meaning that the difference in the estimate \\(\\Psi(P_n)\\) and the true parameter (\\(\\Psi(P_0)\\)) can be represented in first order by a i.i.d. sum: \\[\\begin{equation}\\label{eqn:IC} \\Psi(P_n) - \\Psi(P_0) = \\frac{1}{n} IC(O_i; \\nu) + o_p(1/\\sqrt{n}) \\end{equation}\\] where \\(IC(O_i; \\nu)\\) (the influence curve or function) is a function of the data and possibly other nuisance parameters \\(\\nu\\). Importantly, such estimators have mean-zero Gaussian limiting distributions; thus, in the univariate case, one has that \\[\\begin{equation}\\label{eqn:limit_dist} \\sqrt{n}(\\Psi(P_n) - \\Psi(P_0)) = N(0, (IC(O_i; \\nu))^2), \\end{equation}\\] so that inference for the estimator of interest may be obtained in terms of the influence function. For this simple case, a 95% confidence interval may be derived as: \\[\\begin{equation}\\label{eqn:CI} \\Psi(P^{\\star}_n) \\pm 1.96 \\sqrt{\\frac{\\hat{\\sigma}^2}{n}}, \\end{equation}\\] where \\(SE=\\sqrt{\\frac{\\hat{\\sigma}^2}{n}}\\) and \\(\\hat{\\sigma}^2\\) is the sample variance of the estimated IC’s: \\(IC(O; \\hat{\\nu})\\). One can use the functional delta method to derive the influence curve if a parameter of interest may be written as a function of other asymptotically linear estimators. Thus, we can derive robust inference for parameters that are estimated by fitting complex, machine learning algorithms and these methods are computationally quick (do not rely on re-sampling based methods like the bootstrap). 4.2 Learning Objectives Use tmle3 to estimate an Average Treatment Effect (ATE) Understand tmle3 “Specs” Fit tmle3 for a custom set of parameters Use the delta method to estimate transformations of parameters 4.3 Easy-Bake Example: tmle3 for ATE We’ll illustrate the most basic use of TMLE using the WASH Benefits data introduced earlier and estimating an Average Treatment Effect (ATE). As a reminder, the ATE is identified with the following statistical parameter (under assumptions): \\(ATE = \\mathbb{E}_0(Y(1)-Y(0)) = \\mathbb{E}_0\\left(\\mathbb{E}_0[Y \\mid A=1,W]-\\mathbb{E}_0[Y \\mid A=0,W] \\right)\\) This Easy-Bake implementation consists of the following steps: Load the necessary libraries and data Define the variable roles Create a “Spec” object Define the super learners Fit the TMLE Evaluate the TMLE estimates 0. Load the Data We’ll use the same WASH Benefits data as the earlier chapters: library(data.table) library(tmle3) library(sl3) washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) 1. Define the variable roles We’ll use the common \\(W\\) (covariates), \\(A\\) (treatment/intervention), \\(Y\\) (outcome) data structure. tmle3 needs to know what variables in the dataset correspond to each of these roles. We use a list of character vectors to tell it. We call this a “Node List” as it corresponds to the nodes in a Directed Acyclic Graph (DAG), a way of displaying causal relationships between variables. node_list &lt;- list( W = c( &quot;month&quot;, &quot;aged&quot;, &quot;sex&quot;, &quot;momage&quot;, &quot;momedu&quot;, &quot;momheight&quot;, &quot;hfiacat&quot;, &quot;Nlt18&quot;, &quot;Ncomp&quot;, &quot;watmin&quot;, &quot;elec&quot;, &quot;floor&quot;, &quot;walls&quot;, &quot;roof&quot;, &quot;asset_wardrobe&quot;, &quot;asset_table&quot;, &quot;asset_chair&quot;, &quot;asset_khat&quot;, &quot;asset_chouki&quot;, &quot;asset_tv&quot;, &quot;asset_refrig&quot;, &quot;asset_bike&quot;, &quot;asset_moto&quot;, &quot;asset_sewmach&quot;, &quot;asset_mobile&quot; ), A = &quot;tr&quot;, Y = &quot;whz&quot; ) Handling Missingness Currently, missingness in tmle3 is handled in a fairly simple way: Missing covariates are median (for continuous) or mode (for discrete) imputed, and additional covariates indicating imputation are generated Observations missing either treatment or outcome variables are excluded. We plan to implement IPCW-TMLE to more efficiently handle missingness in the treatment and outcome variables. These steps are implemented in the process_missing function in tmle3: processed &lt;- process_missing(washb_data, node_list) washb_data &lt;- processed$data node_list &lt;- processed$node_list 2. Create a “Spec” Object tmle3 is general, and allows most components of the TMLE procedure to be specified in a modular way. However, most end-users will not be interested in manually specifying all of these components. Therefore, tmle3 implements a tmle3_Spec object that bundles a set of components into a specification that, with minimal additional detail, can be run by an end-user. We’ll start with using one of the specs, and then work our way down into the internals of tmle3. ate_spec &lt;- tmle_ATE( treatment_level = &quot;Nutrition + WSH&quot;, control_level = &quot;Control&quot; ) 3. Define the Relevant Super Learners Currently, the only other thing a user must define are the sl3 learners used to estimate the relevant factors of the likelihood: Q and g. This takes the form of a list of sl3 learners, one for each likelihood factor to be estimated with sl3: # choose base learners lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_xgboost &lt;- make_learner(Lrnr_xgboost) # define metalearners appropriate to data types ls_metalearner &lt;- make_learner(Lrnr_nnls) mn_metalearner &lt;- make_learner( Lrnr_solnp, metalearner_linear_multinomial, loss_loglik_multinomial ) sl_Y &lt;- Lrnr_sl$new( learners = list(lrnr_mean, lrnr_xgboost), metalearner = ls_metalearner ) sl_A &lt;- Lrnr_sl$new( learners = list(lrnr_mean, lrnr_xgboost), metalearner = mn_metalearner ) learner_list &lt;- list(A = sl_A, Y = sl_Y) Here, we use a Super Learner as defined in the previous sl3 section. In the future, we plan to include reasonable default learners. 4. Fit the TMLE We now have everything we need to fit the tmle using tmle3: tmle_fit &lt;- tmle3(ate_spec, washb_data, node_list, learner_list) 5. Evaluate the Estimates We can see the summary results by printing the fit object. Alternatively, we can extra results from the summary by indexing into it: print(tmle_fit) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002440166 0.002494379 se lower upper psi_transformed lower_transformed 1: 0.05066932 -0.09681566 0.1018044 0.002494379 -0.09681566 upper_transformed 1: 0.1018044 estimates &lt;- tmle_fit$summary$psi_transformed print(estimates) [1] 0.002494379 4.4 tmle3 Components Now that we’ve successfully used a spec to obtain a TML estimate, let’s look under the hood at the components. The spec has a number of functions that generate the objects necessary to define and fit a TMLE. 4.4.1 tmle3_task First is, a tmle3_Task, analogous to an sl3_Task, containing the data we’re fitting the TMLE to, as well as an NPSEM generated from the node_list defined above, describing the variables and their relationships. tmle_task &lt;- ate_spec$make_tmle_task(washb_data, node_list) tmle_task$npsem $W tmle3_Node: W Variables: month, aged, sex, momedu, hfiacat, Nlt18, Ncomp, watmin, elec, floor, walls, roof, asset_wardrobe, asset_table, asset_chair, asset_khat, asset_chouki, asset_tv, asset_refrig, asset_bike, asset_moto, asset_sewmach, asset_mobile, momage, momheight, delta_momage, delta_momheight Parents: $A tmle3_Node: A Variables: tr Parents: W $Y tmle3_Node: Y Variables: whz Parents: A, W 4.4.2 Initial Likelihood Next, is an object representing the likelihood, factorized according to the NPSEM described above: initial_likelihood &lt;- ate_spec$make_initial_likelihood( tmle_task, learner_list ) print(initial_likelihood) W: Lf_emp A: LF_fit Y: LF_fit These components of the likelihood indicate how the factors were estimated: the marginal distribution of \\(W\\) was estimated using NP-MLE, and the conditional distributions of \\(A\\) and \\(Y\\) were estimated using sl3 fits (as defined with the learner_list) above. We can use this in tandem with the tmle_task object to obtain likelihood estimates for each observation: initial_likelihood$get_likelihoods(tmle_task) W A Y 1: 0.0002129925 0.2482971 -0.6616029 2: 0.0002129925 0.2540885 -0.6351630 3: 0.0002129925 0.2578671 -0.6232142 4: 0.0002129925 0.2756704 -0.6033917 5: 0.0002129925 0.2532059 -0.5480529 --- 4691: 0.0002129925 0.1337394 -0.4698893 4692: 0.0002129925 0.1263632 -0.4882987 4693: 0.0002129925 0.1265693 -0.5709865 4694: 0.0002129925 0.1678060 -0.8143882 4695: 0.0002129925 0.1295294 -0.5452056 4.4.3 Targeted Likelihood (updater) We also need to define a “Targeted Likelihood” object. This is a special type of likelihood that is able to be updated using an tmle3_Update object. This object defines the update strategy (e.g. submodel, loss function, CV-TMLE or not, etc). targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) When constructing the targeted likelihood, you can specify different update options. See the documentation for tmle3_Update for details of the different options. For example, you can disable CV-TMLE (the default in tmle3) as follows: targeted_likelihood_no_cv &lt;- Targeted_Likelihood$new(initial_likelihood, updater = list(cvtmle = FALSE) ) 4.4.4 Parameter Mapping Finally, we need to define the parameters of interest. Here, the spec defines a single parameter, the ATE. In the next section, we’ll see how to add additional parameters. tmle_params &lt;- ate_spec$make_params(tmle_task, targeted_likelihood) print(tmle_params) [[1]] Param_ATE: ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 4.4.5 Putting it all together Having used the spec to manually generate all these components, we can now manually fit a tmle3: tmle_fit_manual &lt;- fit_tmle3( tmle_task, targeted_likelihood, tmle_params, targeted_likelihood$updater ) print(tmle_fit_manual) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002365312 0.007351927 se lower upper psi_transformed lower_transformed 1: 0.0508875 -0.09238574 0.1070896 0.007351927 -0.09238574 upper_transformed 1: 0.1070896 The result is equivalent to fitting using the tmle3 function as above. 4.5 Fitting tmle3 with multiple parameters Above, we fit a tmle3 with just one parameter. tmle3 also supports fitting multiple parameters simultaneously. To illustrate this, we’ll use the tmle_TSM_all spec: tsm_spec &lt;- tmle_TSM_all() targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) all_tsm_params &lt;- tsm_spec$make_params(tmle_task, targeted_likelihood) print(all_tsm_params) [[1]] Param_TSM: E[Y_{A=Control}] [[2]] Param_TSM: E[Y_{A=Handwashing}] [[3]] Param_TSM: E[Y_{A=Nutrition}] [[4]] Param_TSM: E[Y_{A=Nutrition + WSH}] [[5]] Param_TSM: E[Y_{A=Sanitation}] [[6]] Param_TSM: E[Y_{A=WSH}] [[7]] Param_TSM: E[Y_{A=Water}] This spec generates a Treatment Specific Mean (TSM) for each level of the exposure variable. Note that we must first generate a new targeted likelihood, as the old one was targeted to the ATE. However, we can recycle the initial likelihood we fit above, saving us a super learner step. 4.5.1 Delta Method We can also define parameters based on Delta Method Transformations of other parameters. For instance, we can estimate a ATE using the delta method and two of the above TSM parameters: ate_param &lt;- define_param( Param_delta, targeted_likelihood, delta_param_ATE, list(all_tsm_params[[1]], all_tsm_params[[4]]) ) print(ate_param) Param_delta: E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] This can similarly be used to estimate other derived parameters like Relative Risks, and Population Attributable Risks 4.5.2 Fit We can now fit a TMLE simultaneously for all TSM parameters, as well as the above defined ATE parameter all_params &lt;- c(all_tsm_params, ate_param) tmle_fit_multiparam &lt;- fit_tmle3( tmle_task, targeted_likelihood, all_params, targeted_likelihood$updater ) print(tmle_fit_multiparam) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: TSM E[Y_{A=Control}] -0.597539939 -0.623611880 2: TSM E[Y_{A=Handwashing}] -0.609703345 -0.631852129 3: TSM E[Y_{A=Nutrition}] -0.605359130 -0.629177873 4: TSM E[Y_{A=Nutrition + WSH}] -0.595174627 -0.616086726 5: TSM E[Y_{A=Sanitation}] -0.591126610 -0.585274354 6: TSM E[Y_{A=WSH}] -0.534109850 -0.454598371 7: TSM E[Y_{A=Water}] -0.579807128 -0.527605528 8: ATE E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] 0.002365312 0.007525155 se lower upper psi_transformed lower_transformed 1: 0.02971645 -0.68185506 -0.5653687 -0.623611880 -0.68185506 2: 0.04178946 -0.71375797 -0.5499463 -0.631852129 -0.71375797 3: 0.04249393 -0.71246444 -0.5458913 -0.629177873 -0.71246444 4: 0.04143352 -0.69729494 -0.5348785 -0.616086726 -0.69729494 5: 0.04254009 -0.66865139 -0.5018973 -0.585274354 -0.66865139 6: 0.04544601 -0.54367092 -0.3655258 -0.454598371 -0.54367092 7: 0.03884802 -0.60374624 -0.4514648 -0.527605528 -0.60374624 8: 0.05087455 -0.09218712 0.1072374 0.007525155 -0.09218712 upper_transformed 1: -0.5653687 2: -0.5499463 3: -0.5458913 4: -0.5348785 5: -0.5018973 6: -0.3655258 7: -0.4514648 8: 0.1072374 4.6 Stratified Effect Estimates TMLE can also be applied to estimate effects in in strata of a baseline covariate. The tmle_stratified spec makes it easy to extend an existing spec with stratification. For instance, we can estimate strata specific ATEs as follows: \\(ATE = \\mathbb{E}_0(Y(1)-Y(0) \\mid V=v ) = \\mathbb{E}_0\\left(\\mathbb{E}_0[Y \\mid A=1,W]-\\mathbb{E}_0[Y \\mid A=0,W] \\mid V=v \\right)\\) For example, we can stratify the above ATE spec to estimate the ATE in strata of sex: stratified_ate_spec &lt;- tmle_stratified(ate_spec, &quot;sex&quot;) stratified_fit &lt;- tmle3(stratified_ate_spec, washb_data, node_list, learner_list) print(stratified_fit) A tmle3_Fit that took 1 step(s) type param 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 2: stratified ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] | V=male 3: stratified ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] | V=female init_est tmle_est se lower upper psi_transformed 1: 0.002348573 0.009762099 0.05099241 -0.0901812 0.1097054 0.009762099 2: 0.002043759 0.035573930 0.07639247 -0.1141526 0.1853004 0.035573930 3: 0.002652220 -0.015950963 0.06759695 -0.1484386 0.1165366 -0.015950963 lower_transformed upper_transformed 1: -0.0901812 0.1097054 2: -0.1141526 0.1853004 3: -0.1484386 0.1165366 This TMLE is consistent for both the marginal ATE as well as the ATEs in strata of V. For continuous V, this could be extended using a working Marginal Structural Model (MSM), although that has not yet been implemented in tmle3. 4.7 Exercise Follow the steps below to estimate an average treatment effect using data from the Collaborative Perinatal Project (CPP), available in the sl3 package. To simplify this example, we define a binary intervention variable, parity01 – an indicator of having one or more children before the current child and a binary outcome, haz01 – an indicator of having an above average height for age. Work with a buddy/team. You have 20 minutes. In the etherpad, submit your group’s answers to the following: Interpret the tmle3 fit both causally and statistically. Did your group face any challenges? Any additional comments/questions about this tmle3 section of the workshop? # load the data set data(cpp) cpp &lt;- cpp[!is.na(cpp[, &quot;haz&quot;]), ] cpp$parity01 &lt;- as.numeric(cpp$parity &gt; 0) cpp[is.na(cpp)] &lt;- 0 cpp$haz01 &lt;- as.numeric(cpp$haz &gt; 0) Define the variable roles \\((W,A,Y)\\) by creating a list of these nodes. Include the following baseline covariates in \\(W\\): apgar1, apgar5, gagebrth, mage, meducyrs, sexn. Both \\(A\\) and \\(Y\\) are specified above. Define a tmle3_Spec object for the ATE, tmle_ATE(). Using the same base learning libraries defined above, specify sl3 base learners for estimation of \\(Q = E(Y|A,Y)\\) and \\(g=P(A|W)\\). Define the metalearner like below metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_binomial, learner_function = metalearner_logistic_binomial ) Define one super learner for estimating \\(Q\\) and another for estimating \\(g\\). Use the metalearner above for both \\(Q\\) and \\(g\\) super learners. Create a list of the two super learners defined in Step 5 and call this object learner_list. The list names should be A (defining the super learner for estimating \\(g\\)) and Y (defining the super learner for estimating \\(Q\\)). Fit the tmle with the tmle3 function by specifying (1) the tmle3_Spec, which we defined in Step 2; (2) the data; (3) the list of nodes, which we specified in Step 1; and (4) the list of super learners for estimating \\(g\\) and \\(Q\\), which we defined in Step 6. Note: Like before, you will need to make a data copy to deal with data.table weirdness (cpp2 &lt;- data.table::copy(cpp)) and use cpp2 as the data. 4.8 Summary tmle3 is a general purpose framework for generating TML estimates. The easiest way to use it is to use a predefined spec, allowing you to just fill in the blanks for the data, variable roles, and sl3 learners. However, digging under the hood allows users to specify a wide range of TMLEs. In the next sections, we’ll see how this framework can be used to estimate advanced parameters such as optimal treatments and shift interventions. References "],
["r6.html", "Chapter 5 A Primer on the R6 Class System 5.1 Classes, Fields, and Methods 5.2 Object Oriented Programming: Python and R", " Chapter 5 A Primer on the R6 Class System A central goal of the Targeted Learning statistical paradigm is to estimate scientifically relevant parameters in realistic (usually nonparametric) models. The tlverse is designed using basic OOP principles and the R6 OOP framework. While we’ve tried to make it easy to use the tlverse packages without worrying much about OOP, it is helpful to have some intuition about how the tlverse is structured. Here, we briefly outline some key concepts from OOP. Readers familiar with OOP basics are invited to skip this section. 5.1 Classes, Fields, and Methods The key concept of OOP is that of an object, a collection of data and functions that corresponds to some conceptual unit. Objects have two main types of elements: fields, which can be thought of as nouns, are information about an object, and methods, which can be thought of as verbs, are actions an object can perform. Objects are members of classes, which define what those specific fields and methods are. Classes can inherit elements from other classes (sometimes called base classes) – accordingly, classes that are similar, but not exactly the same, can share some parts of their definitions. Many different implementations of OOP exist, with variations in how these concepts are implemented and used. R has several different implementations, including S3, S4, reference classes, and R6. The tlverse uses the R6 implementation. In R6, methods and fields of a class object are accessed using the $ operator. For a more thorough introduction to R’s various OOP systems, see http://adv-r.had.co.nz/OO-essentials.html, from Hadley Wickham’s Advanced R (Wickham 2014). 5.2 Object Oriented Programming: Python and R OO concepts (classes with inherentence) were baked into Python from the first published version (version 0.9 in 1991). In contrast, R gets its OO “approach” from its predecessor, S, first released in 1976. For the first 15 years, S had no support for classes, then, suddenly, S got two OO frameworks bolted on in rapid succession: informal classes with S3 in 1991, and formal classes with S4 in 1998. This process continues, with new OO frameworks being periodically released, to try to improve the lackluster OO support in R, with reference classes (R5, 2010) and R6 (2014). Of these, R6 behaves most like Python classes (and also most like OOP focused languages like C++ and Java), including having method definitions be part of class definitions, and allowing objects to be modified by reference. References "],
["references.html", "References", " References "]
]
